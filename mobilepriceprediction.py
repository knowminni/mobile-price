# -*- coding: utf-8 -*-
"""MobilePricePrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qGy94bFT0_HBjmA9ODUEElzjyinotDi6
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

import warnings
warnings.filterwarnings('ignore')

"""### **Classification Models:**
    1. Logistic Regression
    2. Logistic Regression with Cross Validator
    3. Stochastic Gradient Descent Classifier
    4. Gaussian Naive Bayes
    5. K Nearest Neighbors
    6. Random Forest Classifier
    7. Support Vector Machine
"""

from google.colab import files
import io

from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, SGDClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

from sklearn.model_selection import GridSearchCV, train_test_split, RandomizedSearchCV
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.externals import joblib

uploaded = files.upload()

data = pd.read_csv(io.BytesIO(uploaded['train.csv']))
data

data.head()

data.info()

data.describe()

names = ['Battery', 'Bluetooth', 'ClockSpeed', 'DualSim', 'FrontCam',
         'FourG', 'Internal', 'Depth', 'Weight', 'NumCores',
         'PrimaryCam', 'PxHeight', 'PxWidth', 'Ram', 'ScHeight', 'ScWidth',
         'TalkTime', 'ThreeG', 'Touch', 'WiFi', 'PriceRange']

data.columns = names
data

num_col = data.select_dtypes(include = np.number).columns
categ_col = data.select_dtypes(exclude = np.number).columns

print("\n Numerical Columns: ", num_col)
print("\n Categorical Columns: ", categ_col)

# Checking for NA values

print(data.isna().sum())
print(data.shape)

sns.countplot(y = data['PriceRange'], data = data)
plt.xlabel('Count of each Target class')
plt.ylabel('Target Classes')
plt.show()

"""Target Variable 'Price Range' is equally distributed."""

data.hist(figsize = (20, 12), bins = 15)
plt.title('Feature Distribution')
plt.show()

plt.figure(figsize = (30, 20), dpi = 80)
p = sns.heatmap(data[num_col].corr(), annot = True, center = 0, cmap = 'RdYlGn')

fig, ax = plt.subplots(nrows = 7, ncols = 3, figsize = (20,25))
plt.title('Individual Features by Class')
row = 0
col = 0
for i in range(len(data.columns)):
    if col > 2:
        row += 1
        col = 0
    axes = ax[row, col]
    sns.boxplot(x = 'PriceRange', y = data.columns[i], data = data, ax = axes)
    col += 1

plt.tight_layout()
plt.show()

data.head()

X = data.drop(['PriceRange'], axis = 1)
y = data['PriceRange']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = np.random)

def evaluateModel(actual, prediction):
    print('\n\n\nConfusion Matrix:\n', confusion_matrix(actual, prediction))
    print('\n\nAccuracy Score:  {:.2f}%'.format(accuracy_score(actual, prediction)*100))
    print('\n\nClassification Report:\n', classification_report(actual, prediction))

def mean_absolute_percentage_error(actual, prediction):
    y_true, y_pred = np.array(actual), np.array(prediction)
    return np.mean(np.abs((actual - prediction)/ actual)) * 100

def modelMetrics(actual, prediction):
    print('R2 Score: ',r2_score(actual, prediction))
    print('MAE Score: ', mean_absolute_error(actual, prediction))
    print('MSE Score: ', mean_squared_error(actual, prediction))
    print('MAPE Score: ', mean_absolute_percentage_error(actual, prediction))

lr = LogisticRegression()
lr.fit(X_train, y_train)
print('Logistic Regression Model: \n', lr)
lrpred = lr.predict(X_test)

modelMetrics(y_test, lrpred)

evaluateModel(y_test, lrpred)

lr2 = LogisticRegressionCV()
lr2.fit(X_train, y_train)
print('Logistic Regression Model with Cross Validation: \n', lr2)
lrcv = lr2.predict(X_test)

modelMetrics(y_test, lrcv)

evaluateModel(y_test, lrcv)

sg = SGDClassifier()
sg.fit(X_train, y_train)
print('Stochastic Gradient Descent Classifier: \n', sg)
sgpred = sg.predict(X_test)

modelMetrics(y_test, sgpred)

evaluateModel(y_test, sgpred)

nb = GaussianNB()
nb.fit(X_train, y_train)
print('Gaussian Naive Bayes Model: \n', nb)
nbpred = nb.predict(X_test)

modelMetrics(y_test, nbpred)

evaluateModel(y_test, nbpred)

kn = KNeighborsClassifier()
kn.fit(X_train, y_train)
print('K-Nearest Neighbors Classifier Model: \n', kn)
knpred = kn.predict(X_test)

modelMetrics(y_test, knpred)

evaluateModel(y_test, knpred)

rf = RandomForestClassifier()
rf.fit(X_train, y_train)
print('Random Forest Classifier Model: \n', rf)
rfpred = rf.predict(X_test)

sup = SVC()
sup.fit(X_train, y_train)
print('Support Vector Machine Model: \n', sup)
suppred = sup.predict(X_test)

modelMetrics(y_test, suppred)

evaluateModel(y_test, suppred)